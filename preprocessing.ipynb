{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d6be581d66d6041584e8891c467237f97011dc2651abe3e7807bbb1a74ce6485"
   }
  },
  "interpreter": {
   "hash": "d6be581d66d6041584e8891c467237f97011dc2651abe3e7807bbb1a74ce6485"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# formats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_to_wave(src,dst):                                                         \n",
    "    sound = AudioSegment.from_mp3(src)\n",
    "    sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# files                                                                         \n",
    "m_mp3 = \"audios/male_voice.mp3\"\n",
    "m_wav = \"audios/male_voice.wav\"\n",
    "fe_mp3 = \"audios/female_voice.mp3\"\n",
    "fe_wav = \"audios/female_voice.wav\"\n",
    "\n",
    "convert_mp3_to_wave(m_mp3,m_wav)\n",
    "convert_mp3_to_wave(fe_mp3,fe_wav)"
   ]
  },
  {
   "source": [
    "# mixing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required library\n",
    "from pydub import AudioSegment, effects\n",
    "from pydub.playback import play \n",
    "\n",
    "def describe_wave(wav_file):\n",
    "    # To find frame rate of song/file\n",
    "    print('frame_rate: ',wav_file.frame_rate)\n",
    "    # Find Maximum amplitude\n",
    "    print('maximum amplitude: ',wav_file.max)\n",
    "    # To know length of audio file\n",
    "    print('length of file: ',len(wav_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frame_rate:  22050\nmaximum amplitude:  32392\nlength of file:  1802\nframe_rate:  22050\nmaximum amplitude:  32393\nlength of file:  2011\n"
     ]
    }
   ],
   "source": [
    "# import the audio file\n",
    "m_wav_audio = AudioSegment.from_file(file=m_wav, format=\"wav\")\n",
    "fe_wav_audio = AudioSegment.from_file(file=fe_wav, format=\"wav\")\n",
    "normalized_m_wav_audio = effects.normalize(m_wav_audio)\n",
    "normalized_fe_wav_audio = effects.normalize(fe_wav_audio)\n",
    "\n",
    "describe_wave(normalized_m_wav_audio)\n",
    "describe_wave(normalized_fe_wav_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(au1,au2):\n",
    "    output = effects.normalize(au1.overlay(au2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10+1):\n",
    "    c = 10-i\n",
    "    res_fe = mix_audio(normalized_fe_wav_audio-c,normalized_m_wav_audio)\n",
    "    res_fe.export(os.path.join(\"audios\",\"merged\",f\"fe{-c:+d}.wav\"),format=\"wav\")\n",
    "    res_m = mix_audio(normalized_fe_wav_audio,normalized_m_wav_audio-c)\n",
    "    res_m.export(os.path.join(\"audios\",\"merged\",f\"m{-c:+d}.wav\"),format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'posixpath' from '/home/zyi103/anaconda3/lib/python3.7/posixpath.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "frame_rate:  22050\nmaximum amplitude:  32393\nlength of file:  2116\nframe_rate:  22050\nmaximum amplitude:  32392\nlength of file:  1802\n"
     ]
    }
   ],
   "source": [
    "path_root =\"audios\"\n",
    "path_folder = \"female-kitchen-female-garage\"\n",
    "path = os.path.join(path_root, path_folder)\n",
    "garage_audio = \"female_voice_garage.wav\"\n",
    "kitchen_audio = \"female_voice_kitchen.wav\"\n",
    "\n",
    "garage_wav_audio = AudioSegment.from_file(file=os.path.join(path,garage_audio), format=\"wav\")\n",
    "kitchen_wav_audio = AudioSegment.from_file(file=os.path.join(path,kitchen_audio), format=\"wav\")\n",
    "normalized_garage_wav_audio = effects.normalize(garage_wav_audio)\n",
    "normalized_kitchen_wav_audio = effects.normalize(kitchen_wav_audio)\n",
    "\n",
    "describe_wave(normalized_garage_wav_audio)\n",
    "describe_wave(normalized_kitchen_wav_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    c = 10-1-i\n",
    "    res_garage = mix_audio(normalized_garage_wav_audio-c,normalized_kitchen_wav_audio)\n",
    "    res_garage.export(os.path.join(path,\"merged\",f\"garage{-c:+d}.wav\"),format=\"wav\")\n",
    "    res_kitchen = mix_audio(normalized_garage_wav_audio,normalized_kitchen_wav_audio-c)\n",
    "    res_kitchen.export(os.path.join(path,\"merged\",f\"kitchen{-c:+d}.wav\"),format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}